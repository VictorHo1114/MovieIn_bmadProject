# app/services/embedding_service.py
"""
å‘é‡èªç¾©æœå°‹æœå‹™
ä½¿ç”¨ OpenAI Embeddings é€²è¡Œé›»å½±æ¨è–¦çš„èªç¾©ç›¸ä¼¼åº¦è¨ˆç®—
"""
import os
import json
import random
import numpy as np
from typing import List, Dict, Any, Optional
from openai import OpenAI
from sqlalchemy import create_engine, text
from sqlalchemy.orm import Session

# OpenAI å®¢æˆ¶ç«¯
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ä½¿ç”¨ text-embedding-3-smallï¼ˆä¾¿å®œä¸”æ•ˆæœå¥½ï¼‰
EMBEDDING_MODEL = "text-embedding-3-small"
EMBEDDING_DIM = 1536


def get_embedding(text: str) -> List[float]:
    """
    ç²å–æ–‡æœ¬çš„ embedding å‘é‡
    
    æˆæœ¬ï¼š~$0.00002 per 1K tokens
    """
    if not text or not text.strip():
        # ç©ºæ–‡æœ¬è¿”å›é›¶å‘é‡
        return [0.0] * EMBEDDING_DIM
    
    response = client.embeddings.create(
        model=EMBEDDING_MODEL,
        input=text
    )
    return response.data[0].embedding


def cosine_similarity(vec1: List[float], vec2: List[float]) -> float:
    """
    è¨ˆç®—å…©å€‹å‘é‡çš„ cosine similarity
    
    è¿”å›å€¼ç¯„åœï¼š[-1, 1]ï¼Œè¶Šæ¥è¿‘ 1 è¡¨ç¤ºè¶Šç›¸ä¼¼
    """
    v1 = np.array(vec1)
    v2 = np.array(vec2)
    
    dot_product = np.dot(v1, v2)
    norm_v1 = np.linalg.norm(v1)
    norm_v2 = np.linalg.norm(v2)
    
    if norm_v1 == 0 or norm_v2 == 0:
        return 0.0
    
    return float(dot_product / (norm_v1 * norm_v2))


def store_movie_embedding(
    db_session: Session,
    tmdb_id: int,
    overview: str
) -> None:
    """
    è¨ˆç®—ä¸¦å„²å­˜é›»å½±çš„ embedding
    """
    try:
        embedding = get_embedding(overview)
        embedding_json = json.dumps(embedding)
        
        # ä½¿ç”¨ UPSERT (PostgreSQL) - Phase 1 ä¿®å¾©ï¼šä½¿ç”¨æ­£ç¢ºçš„ schema
        query = text("""
            INSERT INTO movie_vectors (tmdb_id, embedding, embedding_text, embedding_version, updated_at)
            VALUES (:tmdb_id, :embedding, :embedding_text, :embedding_version, now())
            ON CONFLICT (tmdb_id) 
            DO UPDATE SET 
                embedding = EXCLUDED.embedding,
                embedding_text = EXCLUDED.embedding_text,
                embedding_version = EXCLUDED.embedding_version,
                updated_at = now()
        """)
        
        db_session.execute(query, {
            "tmdb_id": tmdb_id,
            "embedding": embedding_json,
            "embedding_text": overview,
            "embedding_version": "text-embedding-3-small"
        })
        db_session.commit()
    except Exception as e:
        db_session.rollback()
        raise e


async def get_stored_embeddings(
    db_session: Session,
    tmdb_ids: List[int]
) -> Dict[int, List[float]]:
    """
    æ‰¹æ¬¡å–å¾—å·²å„²å­˜çš„ embeddings
    
    è¿”å›ï¼š{tmdb_id: embedding_vector}
    """
    if not tmdb_ids:
        return {}
    
    query = text("""
        SELECT tmdb_id, embedding
        FROM movie_vectors
        WHERE tmdb_id = ANY(:ids)
    """)
    
    result = db_session.execute(query, {"ids": tmdb_ids})
    
    embeddings = {}
    for row in result:
        tmdb_id = row[0]
        embedding_data = row[1]
        # ä¿®å¾©ï¼šJSONB é¡å‹å·²ç¶“æ˜¯ listï¼Œä¸éœ€è¦ json.loads()
        if isinstance(embedding_data, str):
            embeddings[tmdb_id] = json.loads(embedding_data)
        else:
            embeddings[tmdb_id] = embedding_data  # å·²ç¶“æ˜¯ list
    
    return embeddings


def calculate_diversity_score(
    movies: List[Dict[str, Any]],
    selected_movies: List[Dict[str, Any]]
) -> Dict[int, float]:
    """
    è¨ˆç®—å¤šæ¨£æ€§åˆ†æ•¸ï¼Œé™ä½èˆ‡å·²é¸é›»å½±ç›¸ä¼¼çš„é›»å½±æ¬Šé‡
    
    åƒæ•¸ï¼š
        movies: å€™é¸é›»å½±åˆ—è¡¨
        selected_movies: å·²é¸æ“‡çš„é›»å½±åˆ—è¡¨
    
    è¿”å›ï¼š
        {tmdb_id: diversity_score}ï¼Œç¯„åœ [0, 1]
    """
    if not selected_movies:
        # æ²’æœ‰å·²é¸é›»å½±æ™‚ï¼Œæ‰€æœ‰é›»å½±çš„å¤šæ¨£æ€§åˆ†æ•¸éƒ½æ˜¯ 1.0
        return {movie["id"]: 1.0 for movie in movies}
    
    diversity_scores = {}
    
    for movie in movies:
        # è¨ˆç®—èˆ‡å·²é¸é›»å½±çš„ã€Œå·®ç•°åº¦ã€
        genre_ids = set(movie.get("genre_ids", []))
        
        # ä¿®å¾©ï¼šè™•ç† release_date å¯èƒ½æ˜¯ datetime.date æˆ– string
        release_date = movie.get("release_date")
        if release_date:
            if hasattr(release_date, 'year'):
                release_year = str(release_date.year)
            elif isinstance(release_date, str) and len(release_date) >= 4:
                release_year = release_date[:4]
            else:
                release_year = None
        else:
            release_year = None
        
        penalties = []
        for selected in selected_movies:
            # é¡å‹é‡ç–Šæ‡²ç½°
            selected_genres = set(selected.get("genre_ids", []))
            genre_overlap = len(genre_ids & selected_genres) / max(len(genre_ids | selected_genres), 1)
            
            # å¹´ä»½æ¥è¿‘æ‡²ç½°
            selected_date = selected.get("release_date")
            if selected_date:
                if hasattr(selected_date, 'year'):
                    selected_year = str(selected_date.year)
                elif isinstance(selected_date, str) and len(selected_date) >= 4:
                    selected_year = selected_date[:4]
                else:
                    selected_year = None
            else:
                selected_year = None
                
            year_penalty = 0.0
            if release_year and selected_year:
                try:
                    year_diff = abs(int(release_year) - int(selected_year))
                    year_penalty = max(0, 1 - year_diff / 10)  # 10å¹´å…§æœ‰æ‡²ç½°
                except:
                    pass
            
            # ç¸½æ‡²ç½° = é¡å‹é‡ç–Š * 0.7 + å¹´ä»½æ¥è¿‘ * 0.3
            penalty = genre_overlap * 0.7 + year_penalty * 0.3
            penalties.append(penalty)
        
        # å¤šæ¨£æ€§åˆ†æ•¸ = 1 - å¹³å‡æ‡²ç½°
        avg_penalty = sum(penalties) / len(penalties)
        diversity_scores[movie["id"]] = max(0.2, 1 - avg_penalty)  # æœ€ä½ 0.2ï¼Œé¿å…å®Œå…¨æ’é™¤
    
    return diversity_scores


async def rerank_by_semantic_similarity(
    query_text: str,
    candidate_movies: List[Dict[str, Any]],
    db_session: Session,
    top_k: int = 10,
    diversity_weight: float = 0.3,  # å¤šæ¨£æ€§æ¬Šé‡
    boost_exact_matches: bool = False,  # æ˜¯å¦æå‡ç²¾ç¢ºåŒ¹é…æ¬Šé‡
    boost_keyword_matches: bool = False,  # æ–°å¢ï¼šæ˜¯å¦æå‡ keyword åŒ¹é…æ¬Šé‡
    randomness: float = 0.3  # éš¨æ©Ÿæ€§åƒæ•¸ï¼ˆ0.0 å®Œå…¨ç¢ºå®šï¼Œ1.0 å®Œå…¨éš¨æ©Ÿï¼‰
) -> List[Dict[str, Any]]:
    """
    ä½¿ç”¨èªç¾©ç›¸ä¼¼åº¦å°å€™é¸é›»å½±é€²è¡Œé‡æ–°æ’åºï¼Œä¸¦åŠ å…¥å¤šæ¨£æ€§æ©Ÿåˆ¶
    
    åƒæ•¸ï¼š
        query_text: ç”¨æˆ¶æŸ¥è©¢æ–‡æœ¬
        candidate_movies: å€™é¸é›»å½±åˆ—è¡¨ï¼ˆä¾†è‡ª TMDBï¼‰
        db_session: è³‡æ–™åº« session
        top_k: è¿”å›å‰ K éƒ¨é›»å½±
        diversity_weight: å¤šæ¨£æ€§æ¬Šé‡ï¼ˆ0.0 = ç´”ç›¸ä¼¼åº¦ï¼Œ1.0 = ç´”å¤šæ¨£æ€§ï¼‰
        boost_exact_matches: æ˜¯å¦æå‡ç²¾ç¢ºåŒ¹é…æ¬Šé‡
        boost_keyword_matches: æ˜¯å¦æå‡ keyword åŒ¹é…æ¬Šé‡
        randomness: éš¨æ©Ÿæ€§åƒæ•¸ï¼ˆ0.0 å®Œå…¨ç¢ºå®šï¼Œ1.0 å®Œå…¨éš¨æ©Ÿï¼‰
    
    è¿”å›ï¼š
        æ’åºå¾Œçš„é›»å½±åˆ—è¡¨ï¼ˆåŒ…å« similarity_scoreï¼‰
    """
    if not candidate_movies:
        return []
    
    # 1. è¨ˆç®—ç”¨æˆ¶æŸ¥è©¢çš„ embedding
    print(f"[Embedding] è¨ˆç®—æŸ¥è©¢ embedding: '{query_text[:50]}...'")
    query_embedding = get_embedding(query_text)
    
    # 2. å–å¾—å€™é¸é›»å½±çš„ embeddings
    tmdb_ids = [movie["id"] for movie in candidate_movies]
    stored_embeddings = await get_stored_embeddings(db_session, tmdb_ids)
    
    print(f"[Embedding] æ‰¾åˆ° {len(stored_embeddings)} / {len(candidate_movies)} éƒ¨é›»å½±çš„ embeddings")
    
    # 3. å°æ–¼æ²’æœ‰ embedding çš„é›»å½±ï¼Œå³æ™‚è¨ˆç®—ä¸¦å„²å­˜
    movies_needing_embedding = [
        movie for movie in candidate_movies 
        if movie["id"] not in stored_embeddings
    ]
    
    if movies_needing_embedding:
        print(f"[Embedding] å³æ™‚è¨ˆç®— {len(movies_needing_embedding)} éƒ¨é›»å½±çš„ embeddings")
        for movie in movies_needing_embedding:
            overview = movie.get("overview", "")
            if overview:
                try:
                    store_movie_embedding(db_session, movie["id"], overview)
                    # é‡æ–°å–å¾—
                    stored_embeddings[movie["id"]] = get_embedding(overview)
                except Exception as e:
                    print(f"[Embedding] è¨ˆç®—å¤±æ•— (tmdb_id={movie['id']}): {e}")
    
    # 4. è¨ˆç®—ç›¸ä¼¼åº¦åˆ†æ•¸
    for movie in candidate_movies:
        tmdb_id = movie["id"]
        if tmdb_id in stored_embeddings:
            similarity = cosine_similarity(query_embedding, stored_embeddings[tmdb_id])
            
            # [æ–°å¢] æ ¹æ“š randomness åƒæ•¸æ·»åŠ å¯æ§çš„éš¨æ©Ÿæ“¾å‹•
            # randomness=0.0 â†’ ç„¡æ“¾å‹•
            # randomness=0.3 â†’ Â±3% æ“¾å‹•
            # randomness=1.0 â†’ Â±10% æ“¾å‹•
            noise_range = randomness * 0.1
            noise = random.uniform(-noise_range, noise_range)
            base_score = max(0, min(1, similarity + noise))
            
            # [æ–°å¢] å¦‚æœæ˜¯ç²¾ç¢ºåŒ¹é…ï¼Œæå‡æ¬Šé‡
            if boost_exact_matches and movie.get("is_exact_match"):
                base_score = min(1.0, base_score * 1.5)  # æå‡ 50%
                print(f"[Embedding] ç²¾ç¢ºåŒ¹é…åŠ æ¬Š: {movie.get('title')} - {base_score:.3f}")
            
            # [æ–°å¢] å¦‚æœæœ‰ keyword åŒ¹é…ï¼Œæå‡æ¬Šé‡
            if boost_keyword_matches and movie.get("has_keyword_match"):
                base_score = min(1.0, base_score * 1.3)  # æå‡ 30%
                print(f"[Embedding] Keyword åŒ¹é…åŠ æ¬Š: {movie.get('title')} - {base_score:.3f}")
            
            movie["similarity_score"] = base_score
        else:
            movie["similarity_score"] = 0.0
    
    # 5. ä½¿ç”¨ Maximal Marginal Relevance (MMR) é¸æ“‡å¤šæ¨£åŒ–çµæœ
    selected_movies = []
    remaining_movies = candidate_movies.copy()
    
    while len(selected_movies) < top_k and remaining_movies:
        # è¨ˆç®—ç•¶å‰å€™é¸é›»å½±çš„å¤šæ¨£æ€§åˆ†æ•¸
        diversity_scores = calculate_diversity_score(remaining_movies, selected_movies)
        
        # è¨ˆç®—ç¶œåˆåˆ†æ•¸ = ç›¸ä¼¼åº¦ * (1 - diversity_weight) + å¤šæ¨£æ€§ * diversity_weight
        for movie in remaining_movies:
            similarity = movie["similarity_score"]
            diversity = diversity_scores.get(movie["id"], 1.0)
            movie["final_score"] = similarity * (1 - diversity_weight) + diversity * diversity_weight
        
        # é¸æ“‡åˆ†æ•¸æœ€é«˜çš„é›»å½±
        remaining_movies.sort(key=lambda x: x["final_score"], reverse=True)
        best_movie = remaining_movies.pop(0)
        selected_movies.append(best_movie)
    
    print(f"[Embedding] è¿”å› {len(selected_movies)} éƒ¨é›»å½±ï¼ŒTop 10 åˆ†æ•¸:")
    for i, movie in enumerate(selected_movies[:10]):
        print(f"  {i+1}. {movie.get('title', 'Unknown')} - ç›¸ä¼¼åº¦:{movie['similarity_score']:.3f}, æœ€çµ‚åˆ†æ•¸:{movie.get('final_score', 0):.3f}")
    
    return selected_movies


# ============================================================================
# ============================================================================
# Phase 3.6: Embedding-First å…¨åº«æœç´¢ â­
# ============================================================================
# 
# åŠŸèƒ½ï¼š
# - å¾æ•´å€‹ movie_vectors è¡¨ï¼ˆ668 éƒ¨é›»å½±ï¼‰æœç´¢èˆ‡æŸ¥è©¢æœ€ç›¸ä¼¼çš„é›»å½±
# - è¨ˆç®— Cosine Similarity
# - è¿”å› Top K å€™é¸ï¼ˆé è¨­ 300ï¼‰
# 
# èˆ‡ rerank_by_semantic_similarity çš„å€åˆ¥ï¼š
# - rerank: å°å·²æœ‰å€™é¸é‡æ–°æ’åºï¼ˆPhase 3.5 ç”¨ï¼‰
# - embedding_similarity_search: å…¨åº«æœç´¢ï¼ˆPhase 3.6 ç”¨ï¼‰
# ============================================================================

async def embedding_similarity_search(
    query_text: str,
    db_session: Session,
    top_k: int = 300,
    min_similarity: float = 0.0
) -> List[Dict[str, Any]]:
    """
    Phase 3.6 æ ¸å¿ƒåŠŸèƒ½ï¼šå…¨åº« Embedding èªç¾©æœç´¢
    
    èˆ‡ rerank_by_semantic_similarity() çš„å€åˆ¥ï¼š
    - rerank: å°å·²æœ‰çš„å€™é¸åˆ—è¡¨é‡æ–°æ’åºï¼ˆPhase 2/3.5 ç”¨ï¼‰
    - embedding_similarity_search: å¾å…¨åº«æœç´¢ï¼ˆPhase 3.6 Primary Engineï¼‰
    
    æµç¨‹ï¼š
    1. è¨ˆç®— query_text çš„ Embedding
    2. å¾ movie_vectors è¡¨æŸ¥è©¢æ‰€æœ‰é›»å½± Embeddings
    3. è¨ˆç®— Cosine Similarity
    4. è¿”å› Top K é«˜åˆ†é›»å½±
    
    Args:
        query_text: ç”¨æˆ¶æŸ¥è©¢æ–‡æœ¬ï¼ˆå·²ç”± embedding_query_generator è™•ç†ï¼‰
        db_session: è³‡æ–™åº« session
        top_k: è¿”å›å‰ K éƒ¨é›»å½±ï¼ˆé è¨­ 300ï¼Œä¾›å¾ŒçºŒ Feature Filteringï¼‰
        min_similarity: æœ€ä½ç›¸ä¼¼åº¦é–¾å€¼ï¼ˆé è¨­ 0.0ï¼Œä¸éæ¿¾ï¼‰
    
    Returns:
        List[Dict]: åŒ…å« tmdb_id, embedding_score, movie åŸºæœ¬è³‡æ–™
        [
            {
                "id": 550,
                "embedding_score": 0.85,
                "embedding_text": "é›»å½± overview åŸæ–‡",
                ...ï¼ˆmovie åŸºæœ¬è³‡æ–™ï¼‰
            }
        ]
    
    Example:
        >>> results = await embedding_similarity_search(
        ...     query_text="A heartwarming story about emotional healing",
        ...     db_session=session,
        ...     top_k=300
        ... )
        >>> len(results)  # 300
        >>> results[0]["embedding_score"]  # 0.85
    """
    print(f"\nğŸ” [Phase 3.6 Embedding Search] å…¨åº«èªç¾©æœç´¢")
    print(f"   - Query: '{query_text[:80]}...'")
    print(f"   - Top K: {top_k}")
    print(f"   - Min Similarity: {min_similarity}")
    print(f"{'-'*70}")
    
    # Step 1: è¨ˆç®— query_text çš„ Embedding
    print(f"[1/4] è¨ˆç®—æŸ¥è©¢ Embedding...")
    query_embedding = get_embedding(query_text)
    
    # Step 2: å¾ DB æŸ¥è©¢æ‰€æœ‰é›»å½±çš„ Embeddings + åŸºæœ¬è³‡æ–™
    print(f"[2/4] å¾ DB æŸ¥è©¢æ‰€æœ‰é›»å½± Embeddings...")
    query = text("""
        SELECT 
            mv.tmdb_id,
            mv.embedding,
            mv.embedding_text,
            m.title,
            m.original_title,
            m.overview,
            m.release_date,
            m.popularity,
            m.vote_average,
            m.vote_count,
            m.genres,
            m.keywords,
            m.mood_tags,
            m.poster_path
        FROM movie_vectors mv
        JOIN movies m ON mv.tmdb_id = m.tmdb_id
        WHERE mv.embedding IS NOT NULL
    """)
    
    result = db_session.execute(query)
    rows = result.fetchall()
    
    print(f"   âœ“ æ‰¾åˆ° {len(rows)} éƒ¨æœ‰ Embedding çš„é›»å½±")
    
    if not rows:
        print(f"   âš ï¸  æ²’æœ‰é›»å½±æœ‰ Embeddingï¼Œè¿”å›ç©ºåˆ—è¡¨")
        return []
    
    # Step 3: è¨ˆç®— Cosine Similarity
    print(f"[3/4] è¨ˆç®— Cosine Similarity...")
    candidates = []
    
    for row in rows:
        tmdb_id = row[0]
        embedding_data = row[1]
        
        # è§£æ embeddingï¼ˆå¯èƒ½æ˜¯ JSONB æˆ– JSON stringï¼‰
        if isinstance(embedding_data, str):
            movie_embedding = json.loads(embedding_data)
        else:
            movie_embedding = embedding_data  # å·²ç¶“æ˜¯ list
        
        # è¨ˆç®—ç›¸ä¼¼åº¦
        similarity = cosine_similarity(query_embedding, movie_embedding)
        
        # éæ¿¾ä½åˆ†
        if similarity < min_similarity:
            continue
        
        # æ§‹å»ºé›»å½±è³‡æ–™
        candidates.append({
            "id": tmdb_id,
            "embedding_score": float(similarity),
            "embedding_text": row[2],
            "title": row[3],
            "original_title": row[4],
            "overview": row[5],
            "release_date": row[6],
            "popularity": float(row[7]) if row[7] else 0.0,
            "vote_average": float(row[8]) if row[8] else 0.0,
            "vote_count": int(row[9]) if row[9] else 0,
            "genres": row[10] if row[10] else [],  # ä½¿ç”¨ genres çµ±ä¸€å‘½å â­
            "keywords": row[11] if row[11] else [],
            "mood_tags": row[12] if row[12] else [],
            "poster_path": row[13]  # Phase 3.6 æ–°å¢ â­
        })
    
    # Step 4: æ’åºä¸¦è¿”å› Top K
    print(f"[4/4] æ’åºä¸¦è¿”å› Top {top_k}...")
    candidates.sort(key=lambda x: x["embedding_score"], reverse=True)
    results = candidates[:top_k]
    
    print(f"   âœ“ è¿”å› {len(results)} éƒ¨é›»å½±")
    print(f"\n   ğŸ“Š Top 10 Embedding Scores:")
    for i, movie in enumerate(results[:10]):
        print(f"      {i+1}. {movie['title'][:40]:40s} - {movie['embedding_score']:.4f}")
    
    print(f"{'-'*70}\n")
    
    return results